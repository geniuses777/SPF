{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190520\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3668 entries, 0 to 3667\n",
      "Data columns (total 7 columns):\n",
      "Date      3668 non-null object\n",
      "Open      3668 non-null object\n",
      "High      3668 non-null object\n",
      "Low       3668 non-null object\n",
      "Close     3668 non-null object\n",
      "Volume    3668 non-null object\n",
      "Change    3667 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 200.7+ KB\n",
      "raw_stock_info:     Open   High    Low  Close   Volume\n",
      "0   Open   High    Low  Close   Volume\n",
      "1  31050  33800  29500  32750  2961457\n",
      "2  33000  34200  32750  33550  1063262\n",
      "3  33450  33500  32250  33300   535730\n",
      "4  33750  33900  33400  33800   479155\n",
      "stock_info.shape:  (3667, 5)\n",
      "stock_info[0]:  [   31050.    33800.    29500.    32750.  2961457.]\n",
      "price.shape:  (3667, 4)\n",
      "price[0]:  [ 31050.  33800.  29500.  32750.]\n",
      "norm_price[0]:  [ 0.3758465   0.43792325  0.34085779  0.41422122]\n",
      "====================================================================================================\n",
      "********************************test정규화: [ 0.99999999]\n",
      "volume.shape:  (3667, 1)\n",
      "volume[0]:  [ 2961457.]\n",
      "norm_volume[0]:  [ 0.04398349]\n",
      "====================================================================================================\n",
      "x.shape:  (3667, 5)\n",
      "x[0]:  [ 0.3758465   0.43792325  0.34085779  0.41422122  0.04398349]\n",
      "x[-1]:  [ 0.06884876  0.06997743  0.05981941  0.06320542  0.01666268]\n",
      "====================================================================================================\n",
      "y[0]:  [ 0.41422122]\n",
      "y[-1]:  [ 0.06320542]\n",
      "[[  3.75846501e-01   4.37923251e-01   3.40857788e-01   4.14221219e-01\n",
      "    4.39834893e-02]\n",
      " [  4.19864560e-01   4.46952596e-01   4.14221219e-01   4.32279910e-01\n",
      "    1.47714996e-02]\n",
      " [  4.30022573e-01   4.31151242e-01   4.02934537e-01   4.26636569e-01\n",
      "    6.65312435e-03]\n",
      " [  4.36794582e-01   4.40180587e-01   4.28893905e-01   4.37923251e-01\n",
      "    5.78247180e-03]\n",
      " [  4.26636569e-01   4.33408578e-01   4.22121896e-01   4.25507901e-01\n",
      "    1.32253007e-03]\n",
      " [  4.26636569e-01   4.36794582e-01   4.24379233e-01   4.28893905e-01\n",
      "    1.18144050e-03]\n",
      " [  4.09706546e-01   4.19864560e-01   3.91647856e-01   4.07449210e-01\n",
      "    1.57105270e-03]\n",
      " [  3.97291196e-01   4.00677201e-01   3.69074492e-01   3.92776524e-01\n",
      "    3.79287491e-03]\n",
      " [  3.82618510e-01   3.98419865e-01   3.76975169e-01   3.92776524e-01\n",
      "    2.04132050e-03]\n",
      " [  4.08577878e-01   4.37923251e-01   4.04063205e-01   4.36794582e-01\n",
      "    5.58681158e-03]\n",
      " [  4.27765237e-01   4.55981941e-01   4.26636569e-01   4.53724605e-01\n",
      "    7.89230569e-03]\n",
      " [  4.40180587e-01   4.50338600e-01   4.24379233e-01   4.45823928e-01\n",
      "    1.91043407e-03]\n",
      " [  4.42437923e-01   4.57110609e-01   4.42437923e-01   4.57110609e-01\n",
      "    1.52308410e-03]\n",
      " [  4.61625282e-01   4.90970655e-01   4.61625282e-01   4.76297968e-01\n",
      "    1.20710840e-02]\n",
      " [  4.67268623e-01   4.75169300e-01   4.60496614e-01   4.69525959e-01\n",
      "    4.37911685e-03]\n",
      " [  4.58239278e-01   4.72911964e-01   4.50338600e-01   4.65011287e-01\n",
      "    4.39461393e-03]\n",
      " [  4.62753950e-01   4.65011287e-01   4.42437923e-01   4.52595937e-01\n",
      "    9.63927407e-04]\n",
      " [  4.59367946e-01   4.66139955e-01   4.52595937e-01   4.62753950e-01\n",
      "    4.99076662e-04]\n",
      " [  4.65011287e-01   4.95485327e-01   4.60496614e-01   4.89841986e-01\n",
      "    7.48005575e-03]\n",
      " [  4.90970655e-01   5.45146727e-01   4.86455982e-01   5.30474041e-01\n",
      "    1.50760395e-02]\n",
      " [  5.23702032e-01   5.23702032e-01   5.02257336e-01   5.07900677e-01\n",
      "    7.80424782e-03]\n",
      " [  5.07900677e-01   5.18058691e-01   4.87584650e-01   4.90970655e-01\n",
      "    3.51166529e-03]\n",
      " [  4.92099323e-01   5.11286682e-01   4.69525959e-01   5.01128668e-01\n",
      "    8.59756888e-03]\n",
      " [  4.96613995e-01   5.07900677e-01   4.84198646e-01   4.93227991e-01\n",
      "    4.04587584e-03]\n",
      " [  4.97742664e-01   5.13544018e-01   4.97742664e-01   5.07900677e-01\n",
      "    5.57899379e-03]\n",
      " [  5.14672686e-01   5.15801354e-01   4.95485327e-01   5.02257336e-01\n",
      "    4.08176381e-03]\n",
      " [  4.96613995e-01   5.06772009e-01   4.46952596e-01   4.55981941e-01\n",
      "    1.46090650e-02]\n",
      " [  4.44695260e-01   4.59367946e-01   4.40180587e-01   4.48081264e-01\n",
      "    5.38935082e-03]] -> [ 0.46275395]\n",
      "X:  Tensor(\"Placeholder:0\", shape=(?, 28, 5), dtype=float32)\n",
      "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
      "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n",
      "hypothesis:  Tensor(\"rnn/transpose:0\", shape=(?, 28, 20), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error(A): 0.028663739562034607, test_error(B): 0.017637567594647408, B-A: -0.0110261719673872\n",
      "epoch: 200, train_error(A): 0.02688721753656864, test_error(B): 0.01679309643805027, B-A: -0.010094121098518372\n",
      "epoch: 300, train_error(A): 0.025674903765320778, test_error(B): 0.0161606315523386, B-A: -0.009514272212982178\n",
      "epoch: 400, train_error(A): 0.02462787553668022, test_error(B): 0.015603396110236645, B-A: -0.009024479426443577\n",
      "epoch: 500, train_error(A): 0.023597540333867073, test_error(B): 0.015095289796590805, B-A: -0.008502250537276268\n",
      "epoch: 600, train_error(A): 0.02259845845401287, test_error(B): 0.014780553057789803, B-A: -0.007817905396223068\n",
      "epoch: 700, train_error(A): 0.02173536829650402, test_error(B): 0.014660949818789959, B-A: -0.007074418477714062\n",
      "epoch: 800, train_error(A): 0.020988885313272476, test_error(B): 0.014289634302258492, B-A: -0.006699251011013985\n",
      "epoch: 900, train_error(A): 0.020480293780565262, test_error(B): 0.014022910967469215, B-A: -0.0064573828130960464\n",
      "epoch: 1000, train_error(A): 0.02006530575454235, test_error(B): 0.013672001659870148, B-A: -0.006393304094672203\n",
      "elapsed_time: 0:01:46.384349\n",
      "elapsed_time per epoch: 0:00:00.106384\n",
      "input_data_column_cnt: 5,output_data_column_cnt: 1,seq_length: 28,rnn_cell_hidden_dim: 20,forget_bias: 1.0,num_stacked_layers: 1,keep_prob: 1.0,epoch_num: 1000,learning_rate: 0.01,train_error: 0.0200653,test_error: 0.013672,min_test_error: 0.013672\n",
      "raw_stock_info:        Open   High    Low  Close   Volume\n",
      "3663  17700  17850  17400  17450  1186623\n",
      "3664  17300  17750  17100  17550  1405086\n",
      "3665  17400  17900  17400  17800  1262556\n",
      "3666  17800  17850  17050  17200  1906449\n",
      "3667  17450  17500  17050  17200  1186151\n",
      "recent_data.shape: (1, 28, 5)\n",
      "recent_data: [[[ 0.13656885  0.14559819  0.13318284  0.14334086  0.0189974 ]\n",
      "  [ 0.1489842   0.16930023  0.14672686  0.16591422  0.05435173]\n",
      "  [ 0.16704289  0.17268623  0.16478555  0.17042889  0.03172622]\n",
      "  [ 0.17042889  0.17607223  0.16478555  0.1738149   0.03377193]\n",
      "  [ 0.17042889  0.1738149   0.16365688  0.16817156  0.02011585]\n",
      "  [ 0.17042889  0.17268623  0.16365688  0.17042889  0.01672861]\n",
      "  [ 0.16591422  0.16930023  0.15462754  0.16817156  0.02557056]\n",
      "  [ 0.16704289  0.17155756  0.16027088  0.16478555  0.01726388]\n",
      "  [ 0.16817156  0.17494357  0.16252822  0.16591422  0.01793355]\n",
      "  [ 0.16704289  0.16930023  0.15914221  0.16027088  0.00848449]\n",
      "  [ 0.15914221  0.16365688  0.1523702   0.15462754  0.01015177]\n",
      "  [ 0.15801354  0.16365688  0.15124153  0.15462754  0.01214064]\n",
      "  [ 0.15914221  0.16027088  0.1241535   0.1241535   0.05748845]\n",
      "  [ 0.12076749  0.12189616  0.11060948  0.11738149  0.04678669]\n",
      "  [ 0.11851016  0.12641084  0.11625282  0.11963883  0.02978286]\n",
      "  [ 0.11963883  0.13431151  0.11512415  0.13205418  0.02491333]\n",
      "  [ 0.12866817  0.13205418  0.11963883  0.12528217  0.01868079]\n",
      "  [ 0.12076749  0.12641084  0.11625282  0.11851016  0.01878415]\n",
      "  [ 0.11963883  0.12189616  0.11173815  0.11286682  0.02559646]\n",
      "  [ 0.10609481  0.10722348  0.09255079  0.09480813  0.04011319]\n",
      "  [ 0.09029345  0.0993228   0.08690745  0.09819413  0.02083529]\n",
      "  [ 0.09706546  0.09706546  0.08013544  0.08013544  0.04180225]\n",
      "  [ 0.08126411  0.08577878  0.07110609  0.0778781   0.03048149]\n",
      "  [ 0.0744921   0.0778781   0.06772009  0.06884876  0.01666995]\n",
      "  [ 0.06546275  0.07562077  0.06094808  0.07110609  0.02003195]\n",
      "  [ 0.06772009  0.07900677  0.06772009  0.07674944  0.0178385 ]\n",
      "  [ 0.07674944  0.0778781   0.05981941  0.06320542  0.0277476 ]\n",
      "  [ 0.06884876  0.06997743  0.05981941  0.06320542  0.01666268]]]\n",
      "test_predict [ 0.07708798]\n",
      "Tomorrow's stock price [ 17814.99804688]\n"
     ]
    }
   ],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date,timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "#########################################################################################################\n",
    "import matplotlib.font_manager as fm\n",
    "#########################################################################################################\n",
    "import pymysql\n",
    "import settings\n",
    "import os\n",
    "import locale\n",
    "#from datetime import date,timedelta\n",
    "\n",
    "#########################################################################################################\n",
    "#\n",
    "# DB테이블 값 조회 (SELECT)\n",
    "#\n",
    "connection = pymysql.connect(host='222.122.86.187', port=3306, user='geniuses777', password='stock7840',\n",
    "                       db='geniuses777', charset='utf8')\n",
    "\n",
    "# 오차율 가져오기\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"select accuracy from company WHERE name='LGD'\"\n",
    "        cursor.execute(\"set names utf8\")\n",
    "        cursor.execute(sql)\n",
    "        result_accuracy = cursor.fetchone()\n",
    "        \n",
    "        for i in result_accuracy:\n",
    "            accuracy = i\n",
    "            \n",
    "finally:\n",
    "    connection.close()\n",
    "#########################################################################################################\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def data_standardization(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.mean()) / x_np.std()\n",
    " \n",
    "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
    "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
    "# Min-Max scaling\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
    " \n",
    "# 정규화된 값을 원래의 값으로 되돌린다\n",
    "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()\n",
    " \n",
    " \n",
    "# 하이퍼파라미터\n",
    "input_data_column_cnt = 5  # 입력데이터의 컬럼 개수(Variable 개수)\n",
    "output_data_column_cnt = 1 # 결과데이터의 컬럼 개수\n",
    " \n",
    "seq_length = 28            # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 20   # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 1.0          # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 1     # stacked LSTM layers 개수\n",
    "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
    " \n",
    "epoch_num = 1000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.01       # 학습률\n",
    " \n",
    "start_date = '2000-01-01' # 최근 10년간 데이터\n",
    "end_date = settings.get_today_str() # 오늘날짜\n",
    "#end_date = date.today() - timedelta(1) # 어제날짜\n",
    "\n",
    "#tocks = 'sk'\n",
    "stocks = ['samsung', 'kakao','cj','lg','sk','dosan','asiana','hanhaw','hyundai','hite','LGD','jeju','naver']\n",
    "\n",
    "# .csv파일을 저장할 디렉토리\n",
    "data_dir = os.path.join(\n",
    "    settings.BASE_DIR, 'chart_data/%s' % (\n",
    "        settings.get_today_str()))     # timestr : 날짜, 시간\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# 추가\n",
    "# samsung\n",
    "#df = fdr.DataReader('005930', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[0]))\n",
    "# kakao\n",
    "#df = fdr.DataReader('035720', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[1]))\n",
    "#CJ\n",
    "#df = fdr.DataReader('001040', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[2]))\n",
    "#LG전자\n",
    "#df = fdr.DataReader('066570', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[3]))\n",
    "#SK\n",
    "#df = fdr.DataReader('034730', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[4]))\n",
    "#DOSAN\n",
    "#df = fdr.DataReader('000150', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[5]))\n",
    "#ASIANA\n",
    "#df = fdr.DataReader('020560', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[6]))\n",
    "#HANHAW\n",
    "#df = fdr.DataReader('000880', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[7]))\n",
    "#HYENDAI\n",
    "#df = fdr.DataReader('005380', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[8]))\n",
    "#HITE\n",
    "#df = fdr.DataReader('000090', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[9]))\n",
    "#lgd\n",
    "df = fdr.DataReader('034220', start_date, end_date)\n",
    "df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[10]))\n",
    "#jeju\n",
    "#df = fdr.DataReader('089590', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[11]))\n",
    "#naver\n",
    "#df = fdr.DataReader('035420', start_date, end_date)\n",
    "#df.to_csv('./chart_data/%s/%s.csv' % (settings.get_today_str(), stocks[12]))\n",
    "\n",
    "print(settings.get_today_str())\n",
    "#yesterday = date.today() - timedelta(1)\n",
    "#print(yesterday.strftime('%Y-%m-%d'))\n",
    "#stock_file_name = 'chart_date\\20190502\\kakao.csv' # 아마존 주가데이터 파일\n",
    "encoding = 'euc-kr' # 문자 인코딩\n",
    "names = ['Date','Open','High','Low','Close','Volume','Change']\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "sydtpath = os.path.join(settings.BASE_DIR, 'chart_data/%s' % (settings.get_today_str()))\n",
    "#stock_code = \"kakao\"\n",
    "fullpath = sydtpath + os.path.sep + stocks[10]  + '.csv'\n",
    "#stock_code + '.csv'\n",
    "raw_dataframe = pd.read_csv(fullpath, names=names, encoding=encoding) #판다스이용 csv파일 로딩\n",
    "raw_dataframe.info() # 데이터 정보 출력\n",
    "######################################################################################################### \n",
    "    \n",
    "# raw_dataframe.drop('Date', axis=1, inplace=True) # 시간열을 제거하고 dataframe 재생성하지 않기\n",
    "del raw_dataframe['Date'] # 위 줄과 같은 효과\n",
    "del raw_dataframe['Change']\n",
    "    \n",
    "\n",
    "print(\"raw_stock_info:\",raw_dataframe.head())    \n",
    "    \n",
    "stock_info = raw_dataframe.values[1:].astype(np.float) # 금액&거래량 문자열을 부동소수점형으로 변환한다\n",
    "print(\"stock_info.shape: \", stock_info.shape)\n",
    "print(\"stock_info[0]: \", stock_info[0])\n",
    "\n",
    "# 데이터 전처리\n",
    "# 가격과 거래량 수치의 차이가 많아나서 각각 별도로 정규화한다\n",
    " \n",
    "# 가격형태 데이터들을 정규화한다\n",
    "# ['Open','High','Low','Close','Adj Close','Volume']에서 'Adj Close'까지 취함\n",
    "# 곧, 마지막 열 Volume를 제외한 모든 열\n",
    "price = stock_info[:,:-1]\n",
    "norm_price = min_max_scaling(price) # 가격형태 데이터 정규화 처리\n",
    "print(\"price.shape: \", price.shape)\n",
    "print(\"price[0]: \", price[0])\n",
    "print(\"norm_price[0]: \", norm_price[0])\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    " \n",
    "a = [[10],[9],[8],[6],[2],[0]]\n",
    "test_price=min_max_scaling(a)\n",
    "print(\"********************************test정규화:\",test_price[0])\n",
    "\n",
    "# 거래량형태 데이터를 정규화한다\n",
    "# ['Open','High','Low','Close','Adj Close','Volume']에서 마지막 'Volume'만 취함\n",
    "# [:,-1]이 아닌 [:,-1:]이므로 주의하자! 스칼라가아닌 벡터값 산출해야만 쉽게 병합 가능\n",
    "volume = stock_info[:,-1:]\n",
    "norm_volume = min_max_scaling(volume) # 거래량형태 데이터 정규화 처리\n",
    "print(\"volume.shape: \", volume.shape)\n",
    "print(\"volume[0]: \", volume[0])\n",
    "print(\"norm_volume[0]: \", norm_volume[0])\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    " \n",
    "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
    "x = np.concatenate((norm_price, norm_volume), axis=1) # axis=1, 세로로 합친다\n",
    "print(\"x.shape: \", x.shape)\n",
    "print(\"x[0]: \", x[0])    # x의 첫 값\n",
    "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    " \n",
    "y = x[:, [-2]] # 타켓은 주식 종가이다\n",
    "print(\"y[0]: \",y[0])     # y의 첫 값\n",
    "print(\"y[-1]: \",y[-1])   # y의 마지막 값\n",
    " \n",
    " \n",
    "dataX = [] # 입력으로 사용될 Sequence Data\n",
    "dataY = [] # 출력(타켓)으로 사용\n",
    " \n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i : i+seq_length]\n",
    "    _y = y[i + seq_length] # 다음 나타날 주가(정답)\n",
    "    if i is 0:\n",
    "        print(_x, \"->\", _y) # 첫번째 행만 출력해 봄\n",
    "    dataX.append(_x) # dataX 리스트에 추가\n",
    "    dataY.append(_y) # dataY 리스트에 추가\n",
    "    \n",
    "\n",
    " \n",
    "# 학습용/테스트용 데이터 생성\n",
    "# 전체 70%를 학습용 데이터로 사용\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "# 나머지(30%)를 테스트용 데이터로 사용\n",
    "test_size = len(dataY) - train_size\n",
    " \n",
    "# 데이터를 잘라 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    " \n",
    "# 데이터를 잘라 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])\n",
    " \n",
    " \n",
    "# 텐서플로우 플레이스홀더 생성\n",
    "# 입력 X, 출력 Y를 생성한다\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
    "print(\"X: \", X)\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"Y: \", Y)\n",
    " \n",
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"targets: \", targets)\n",
    " \n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"predictions: \", predictions)\n",
    "\n",
    "\n",
    "\n",
    "# 모델(LSTM 네트워크) 생성\n",
    "def lstm_cell():\n",
    "    # LSTM셀을 생성\n",
    "    # num_units: 각 Cell 출력 크기\n",
    "    # forget_bias:  to the biases of the forget gate \n",
    "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
    "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    " \n",
    "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
    " \n",
    "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"hypothesis: \", hypothesis)\n",
    " \n",
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# 손실함수로 평균제곱오차를 사용한다\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "# 최적화함수로 AdamOptimizer를 사용한다\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
    "train = optimizer.minimize(loss)\n",
    " \n",
    "# RMSE(Root Mean Square Error)\n",
    "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    " \n",
    "\n",
    "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
    "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
    " \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "# 학습한다\n",
    "start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
    "print('학습을 시작합니다...')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch+1) % 100 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 rmse오차를 구한다\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
    "        train_error_summary.append(train_error)\n",
    " \n",
    "        # 테스트용데이터로 rmse오차를 구한다\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
    "        test_error_summary.append(test_error)\n",
    "        \n",
    "        # 현재 오류를 출력한다\n",
    "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
    "        \n",
    "end_time = datetime.datetime.now() # 종료시간을 기록한다\n",
    "elapsed_time = end_time - start_time # 경과시간을 구한다\n",
    "print('elapsed_time:',elapsed_time)\n",
    "print('elapsed_time per epoch:',elapsed_time/epoch_num)\n",
    " \n",
    " \n",
    "# 하이퍼파라미터 출력\n",
    "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
    "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
    " \n",
    "print(',seq_length:', seq_length, end='')\n",
    "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
    "print(',forget_bias:', forget_bias, end='')\n",
    "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
    "print(',keep_prob:', keep_prob, end='')\n",
    " \n",
    "print(',epoch_num:', epoch_num, end='')\n",
    "print(',learning_rate:', learning_rate, end='')\n",
    " \n",
    "print(',train_error:', train_error_summary[-1], end='')\n",
    "print(',test_error:', test_error_summary[-1], end='')\n",
    "print(',min_test_error:', np.min(test_error_summary))\n",
    "\n",
    "\n",
    "print(\"raw_stock_info:\",raw_dataframe.tail())\n",
    "\n",
    "\n",
    "# 결과 그래프 출력\n",
    "#plt.figure(1)\n",
    "#plt.plot(train_error_summary, 'gold')\n",
    "#plt.plot(test_error_summary, 'b')\n",
    "#plt.xlabel('Epoch(x100)')\n",
    "#plt.ylabel('Root Mean Square Error')\n",
    "#########################################################################################################\n",
    "fontprop = fm.FontProperties(fname=\"a옛날목욕탕L.ttf\", size=13)\n",
    "#########################################################################################################\n",
    " \n",
    "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
    "recent_data = np.array([x[len(x)-seq_length : ]])\n",
    "print(\"recent_data.shape:\", recent_data.shape)\n",
    "print(\"recent_data:\", recent_data)\n",
    "\n",
    "# 역정규화\n",
    "test_predict = reverse_min_max_scaling(price, test_predict)\n",
    "testY = reverse_min_max_scaling(price, testY)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(testY, 'r')\n",
    "plt.plot(test_predict, 'b')\n",
    "\n",
    "#########################################################################################################\n",
    "#plt.xlabel('Time Period', fontproperties=fontprop)\n",
    "#plt.ylabel('Stock Price', fontproperties=fontprop)\n",
    "#plt.title('SK graph')\n",
    "#plt.savefig(\"./chart_picture/sk.png\",dpi=300)\n",
    "#########################################################################################################\n",
    "\n",
    "# 사진 데이터 binary형식으로 바꿔주는 함수\n",
    "def convertToBinaryData(filename):\n",
    "    #Convert digital data to binary format\n",
    "    with open(filename, 'rb') as file:\n",
    "        binaryData = file.read()\n",
    "    return binaryData\n",
    "\n",
    "# 내일 종가를 예측해본다\n",
    "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    "print(\"test_predict\", test_predict[0])\n",
    "test_predict = reverse_min_max_scaling(price,test_predict) # 금액데이터 역정규화한다\n",
    "print(\"Tomorrow's stock price\", test_predict[0]) # 예측한 주가를 출력한다\n",
    "\n",
    "#########################################################################################################\n",
    "#plt.title('[SK] predict graph\\npredict_price : %d                   accuracy : %s' % (test_predict[0], accuracy))\n",
    "plt.title('[LGD] 예측 그래프\\n예측값 : %d \\t\\t\\t\\t\\t\\t\\t오차율 : %s' % (test_predict[0], accuracy), fontproperties=fontprop)\n",
    "#########################################################################################################\n",
    "#plt.title('sk')\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"./chart_picture/LGD.png\",dpi=300)\n",
    "\n",
    "connection = pymysql.connect(host='222.122.86.187',port=3306,user='geniuses777',passwd='stock7840',db='geniuses777',charset='utf8')\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        \n",
    "        sql = 'INSERT INTO company (name, price, image) VALUES (%s, %s, %s) ON DUPLICATE KEY UPDATE price = VALUES(price) , image = VALUES(image)'\n",
    "        image = convertToBinaryData(\".\\chart_picture\\LGD.png\")\n",
    "        cursor.execute(sql, ('LGD', int(test_predict[0]), image))          # 넣으려는 값\n",
    "\n",
    "        connection.commit()\n",
    "\n",
    "finally:\n",
    "    connection.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
